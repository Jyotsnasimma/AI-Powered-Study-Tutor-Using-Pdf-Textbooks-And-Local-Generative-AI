{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42eb255-06bb-4c6b-89d3-c4d935521f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad1caa0-797a-45f2-8fc3-5c8e6fb0ade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.3.67)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.4.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from faiss-cpu) (23.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (2.98)\n",
      "Requirement already satisfied: comtypes in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from pyttsx3) (1.4.11)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (4.53.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.53.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install faiss-cpu\n",
    "!pip install pyttsx3\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install sentence-transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b168ce5b-97b5-44a9-9656-edd40ff20a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymupdf in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (1.26.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a130728d-0f33-4bab-ae50-d1000fc3bc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (3.14.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from SpeechRecognition) (4.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyaudio in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (0.2.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition\n",
    "!pip install pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fe4d84-652f-49d6-947b-597baf28ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 84972\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def load_pdf(path):\n",
    "    doc = fitz.open(\"DSA Full Notes GR-20.pdf\")\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "pdf_path = \"DSA Full Notes GR-20.pdf\"  # Make sure this file is in the same folder as your notebook\n",
    "raw_text = load_pdf(pdf_path)\n",
    "print(\"Text length:\", len(raw_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba74eab1-1d5b-46ac-ad10-e715fada0a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.53.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from faiss-cpu) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n",
    "!pip install faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d957b969-b7bd-4dc4-a5b6-6cae064f8286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 213\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Define your chunking method\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # Each chunk will have ~500 characters\n",
    "    chunk_overlap=100  # Overlap between chunks (helps for continuity)\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(raw_text)\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb6d786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Extracting PDF text...\n",
      "üîÑ Splitting into chunks...\n",
      "‚úÖ PDF split into 26 chunks.\n",
      "üîç Creating FAISS index...\n",
      "‚úÖ Ready! Ask any question (type 'exit' to quit).\n",
      "üîç Searching PDF for relevant content...\n",
      "ü§ñ Generating answer...\n",
      "\n",
      "üí¨ AI Tutor Answer:\n",
      "Data science is the field of study that involves collecting, analyzing, and interpreting data. It involves a combination of mathematics, statistics, computer science, and engineering to gain insights from large amounts of data. Data science is increasingly becoming an essential component of modern businesses and industries, as it enables them to make better decisions, improve their products or services, and optimize their processes. Some key areas of application for data science include:\n",
      "\n",
      "1. Predictive analytics: This is a discipline that uses data to make predictions about future outcomes based on past data. Predictive analytics allows businesses to identify patterns in customer behavior or sales trends and use that information to make informed decisions.\n",
      "\n",
      "2. Data mining: This is the process of uncovering hidden insights from large datasets. Data mining techniques can be used to find patterns, relationships, and trends in data that may not otherwise be apparent. For example, a customer database might contain information about past purchases made by an individual customer. By analyzing this data, data miners can identify patterns that suggest the probability of future purchases.\n",
      "\n",
      "3. Data visualization: This is the process of presenting data in a way that is easy to understand and interpret. Visualizing data using graphs, charts, and other visual aids can help businesses better communicate their insights to stakeholders, including investors and customers.\n",
      "\n",
      "4. Big data analytics: This is the use of large datasets for analytical purposes. Big data involves analyzing vast amounts of structured or unstructured data in real-time to gain insights that can help businesses improve their operations, make more informed decisions, and reduce costs.\n",
      "\n",
      "5. Artificial intelligence (AI): AI is a branch of computer science that enables machines to perform tasks that would typically require human intelligence. AI can be used to analyze data, making predictions or carrying out tasks based on patterns identified by machine learning algorithms. For example, a chatbot could help a customer service department process inquiries more efficiently by analyzing data and identifying patterns in customer behavior.\n",
      "\n",
      "In summary, data science is essential for businesses and industries looking to improve decision-making, optimize processes, and reduce costs.\n",
      "\n",
      "üîä Speaking answer...\n",
      "üëã Exiting AI Tutor. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pyttsx3\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Extract text from PDF\n",
    "# ------------------------------\n",
    "def extract_pdf_text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Split text into chunks\n",
    "# ------------------------------\n",
    "def split_into_chunks(text, chunk_size=500):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Create FAISS index\n",
    "# ------------------------------\n",
    "def create_faiss_index(chunks, model):\n",
    "    embeddings = model.encode(chunks)\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, embeddings\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Find top N best chunks\n",
    "# ------------------------------\n",
    "def find_top_chunks(question, chunks, model, index, top_n=3):\n",
    "    q_embedding = model.encode([question])\n",
    "    distances, indices = index.search(np.array(q_embedding), k=top_n)\n",
    "    return [chunks[i] for i in indices[0]]\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Ask TinyLLaMA using Ollama\n",
    "# ------------------------------\n",
    "def ask_local_llm(context, question):\n",
    "    prompt = f\"\"\"You are a helpful AI tutor. Based only on the textbook content below, answer the question clearly and accurately.\n",
    "\n",
    "Text:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='tinyllama',\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Speak the answer (TTS)\n",
    "# ------------------------------\n",
    "def speak_text(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# ------------------------------\n",
    "# MAIN SCRIPT (Interactive Chat with Voice)\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"DSA Full Notes GR-20.pdf\"  # <-- Your PDF file path\n",
    "\n",
    "    print(\"üìñ Extracting PDF text...\")\n",
    "    full_text = extract_pdf_text(pdf_path)\n",
    "    if not full_text.strip():\n",
    "        print(\"‚ùå Could not extract text from the PDF.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"üîÑ Splitting into chunks...\")\n",
    "    chunks = split_into_chunks(full_text)\n",
    "    print(f\"‚úÖ PDF split into {len(chunks)} chunks.\")\n",
    "\n",
    "    print(\"üîç Creating FAISS index...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    index, embeddings = create_faiss_index(chunks, model)\n",
    "    print(\"‚úÖ Ready! Ask any question (type 'exit' to quit).\")\n",
    "\n",
    "    # Interactive Loop\n",
    "    while True:\n",
    "        question = input(\"\\n‚ùì Your Question: \")\n",
    "        if question.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"üëã Exiting AI Tutor. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        print(\"üîç Searching PDF for relevant content...\")\n",
    "        top_chunks = find_top_chunks(question, chunks, model, index, top_n=3)\n",
    "        combined_context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "        print(\"ü§ñ Generating answer...\\n\")\n",
    "        answer = ask_local_llm(combined_context, question)\n",
    "\n",
    "        print(f\"üí¨ AI Tutor Answer:\\n{answer}\\n\")\n",
    "\n",
    "        # Speak answer\n",
    "        print(\"üîä Speaking answer...\")\n",
    "        speak_text(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d184731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Extracting PDF text...\n",
      "üîÑ Splitting into chunks...\n",
      "‚úÖ PDF split into 26 chunks.\n",
      "üîç Creating FAISS index...\n",
      "‚úÖ Ready! Say 'exit' to quit.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùå Sorry, I couldn't understand. Please try again.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùå Sorry, I couldn't understand. Please try again.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùì You asked: machine learning\n",
      "üîç Searching PDF for relevant content...\n",
      "ü§ñ Generating answer...\n",
      "\n",
      "üí¨ AI Tutor Answer:\n",
      "Sure! Machine learning is a powerful technique for predicting and generating new data based on historical data. One of the most popular machine learning models, which are used to build predictive models, is called support vector machines (SVMs). SVMs work by maximizing the margin between two classes, which is a measure of how different their features (attributes) are compared to each other.\n",
      "\n",
      "The advantage of using SVMs for predicting new data is that they can handle both high-dimensional and noisy data with ease. The algorithm starts by splitting the data into two sets: training and testing sets. In the training set, SVMs learn to classify new data based on features from the training set. Then in the test set, the output of SVMs is compared against the predicted labels, which helps to evaluate their performance. \n",
      "\n",
      "SVMs can also handle outliers in the data. Outliers are rare events with extreme values that deviate significantly from the normal distribution. Outliers can skew the data and make it difficult to accurately predict new data. SVMs can detect and remove outliers, which improves their performance on unseen data.\n",
      "\n",
      "SVMs have been widely used in industries such as finance, healthcare, and logistics for various applications including fraud detection, risk analysis, supply chain optimization, and demand forecasting. They can also be used in natural language processing (NLP) for sentiment analysis, summarization, and natural language generation.\n",
      "\n",
      "Overall, SVMs are a powerful machine learning model that can handle high-dimensional and noisy data while improving prediction performance.\n",
      "\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùì You asked: Malayalam\n",
      "üîç Searching PDF for relevant content...\n",
      "ü§ñ Generating answer...\n",
      "\n",
      "üí¨ AI Tutor Answer:\n",
      "In the given text, there is a question asking whether Malaya Lam's collection of poems published under the title \"Essence of Time\" can be considered as \"a modern version of the Chinese poem,\" while being in Chinese language. Malaya Lam is a poet and writer from Hong Kong. The question is posed at the end of the text, which consists of an excerpt from the book, with a brief description of its contents.\n",
      "\n",
      "Excerpt:\n",
      "\"In the midst of the world's chaos, in the midst of humanity's despair, a gentle whisper of light glimmered like an ember. It was then that Malaya Lam, in her youthful yet mature years, began to write poems filled with an enduring light that will not cease.\"\n",
      "\n",
      "\"As a poet and writer from Hong Kong, Lam has been honored to share this book of poems with the world. Her collection of poems published under the title 'Essence of Time' captures essences of time, while holding onto its essence, in Chinese language. Through her words, she touches the hearts of readers from different parts of the world, making them feel something profound.\"\n",
      "\n",
      "In conclusion:\n",
      "Malaya Lam's poetry collection \"Essence of Time\" is a modern version of traditional Chinese poems that reflects on time's essence in Chinese language. The excerpt describes Lam's passion for writing and her dedication to capturing essences of time through her poetry, making it an essential addition to any collection of modern poets.\n",
      "\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùå Sorry, I couldn't understand. Please try again.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùå Sorry, I couldn't understand. Please try again.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùì You asked: quit\n",
      "üëã Exiting AI Tutor. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Extract text from PDF\n",
    "# ------------------------------\n",
    "def extract_pdf_text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Split text into chunks\n",
    "# ------------------------------\n",
    "def split_into_chunks(text, chunk_size=500):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Create FAISS index\n",
    "# ------------------------------\n",
    "def create_faiss_index(chunks, model):\n",
    "    embeddings = model.encode(chunks)\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, embeddings\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Find top N best chunks\n",
    "# ------------------------------\n",
    "def find_top_chunks(question, chunks, model, index, top_n=3):\n",
    "    q_embedding = model.encode([question])\n",
    "    distances, indices = index.search(np.array(q_embedding), k=top_n)\n",
    "    return [chunks[i] for i in indices[0]]\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Ask TinyLLaMA using Ollama\n",
    "# ------------------------------\n",
    "def ask_local_llm(context, question):\n",
    "    prompt = f\"\"\"You are a helpful AI tutor. Based only on the textbook content below, answer the question clearly and accurately.\n",
    "\n",
    "Text:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='tinyllama',\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Speak the answer (TTS)\n",
    "# ------------------------------\n",
    "def speak_text(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Listen for voice question\n",
    "# ------------------------------\n",
    "def listen_question():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"üé§ Listening... Please speak your question.\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        question = recognizer.recognize_google(audio)\n",
    "        print(f\"‚ùì You asked: {question}\")\n",
    "        return question\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"‚ùå Sorry, I couldn't understand. Please try again.\")\n",
    "        return None\n",
    "    except sr.RequestError:\n",
    "        print(\"‚ùå Voice recognition service is unavailable.\")\n",
    "        return None\n",
    "\n",
    "# ------------------------------\n",
    "# MAIN SCRIPT\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"DSA Full Notes GR-20.pdf\"  # <-- Your PDF file\n",
    "\n",
    "    print(\"üìñ Extracting PDF text...\")\n",
    "    full_text = extract_pdf_text(pdf_path)\n",
    "    if not full_text.strip():\n",
    "        print(\"‚ùå Could not extract text from the PDF.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"üîÑ Splitting into chunks...\")\n",
    "    chunks = split_into_chunks(full_text)\n",
    "    print(f\"‚úÖ PDF split into {len(chunks)} chunks.\")\n",
    "\n",
    "    print(\"üîç Creating FAISS index...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    index, embeddings = create_faiss_index(chunks, model)\n",
    "    print(\"‚úÖ Ready! Say 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        question = listen_question()\n",
    "        if not question:\n",
    "            continue\n",
    "        if question.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"üëã Exiting AI Tutor. Goodbye!\")\n",
    "            speak_text(\"Goodbye! Exiting AI Tutor.\")\n",
    "            break\n",
    "\n",
    "        print(\"üîç Searching PDF for relevant content...\")\n",
    "        top_chunks = find_top_chunks(question, chunks, model, index, top_n=3)\n",
    "        combined_context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "        print(\"ü§ñ Generating answer...\\n\")\n",
    "        answer = ask_local_llm(combined_context, question)\n",
    "\n",
    "        print(f\"üí¨ AI Tutor Answer:\\n{answer}\\n\")\n",
    "        speak_text(answer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cbb68f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Starting accuracy test...\n",
      "\n",
      "Q1: What is predictive analysis?\n",
      "AI Answer: Predictive Analytics refers to the process of using advanced algorithms and statistical techniques to predict future outcomes based on historical data and past patterns. This can be applied in a variety of domains such as healthcare, finance, manufacturing, etc., with the aim of improving decision-making, reducing costs, and enhancing profitability for organizations. Predictive analytics tools utilize machine learning algorithms and data science techniques to analyze historical data and make predictions about future outcomes. By forecasting and predicting, predictive analytics enables organizations to take proactive measures to anticipate and mitigate risks or opportunities, improve performance, and optimize decision-making processes.\n",
      "Expected: Predictive analysis uses historical data and statistical models to predict future outcomes.\n",
      "Similarity Score: 0.77\n",
      "\n",
      "Q2: What is regression?\n",
      "AI Answer: Regresi√≥n (literally \"regression\") is a statistical method used to estimate the relationship between two or more variables in a population. It involves finding the slope, y-intercept, and r value of a line (or straight line) that best describes the data, and then predicting the values of the dependent variable based on the independent variables. In simpler terms, it is a mathematical model used to estimate the relationship between two or more independent variables and one or more dependent variables. Regression analysis can be applied to a wide range of data sets and is often used in various fields such as economics, finance, marketing, and healthcare.\n",
      "Expected: Regression is a supervised learning method used to predict continuous values.\n",
      "Similarity Score: 0.67\n",
      "\n",
      "Q3: What is classification?\n",
      "AI Answer: Classification refers to the process of assigning a label or category to an object based on its features. Classification is useful in many industries, including engineering, healthcare, and marketing, where data needs to be categorized for analysis or communication purposes. Classification can also help organizations make informed decisions by identifying patterns, trends, and relationships between different variables that are relevant to their business goals. The algorithms used for classification are generally based on mathematical models that learn from data and adaptively classify new examples based on the features they capture. Some of the commonly used classification techniques include logistic regression, support vector machines (SVMs), decision trees, random forests, neural networks, and ensemble methods.\n",
      "Expected: Classification is a supervised learning task that assigns data into predefined labels.\n",
      "Similarity Score: 0.72\n",
      "\n",
      "Q4: What are the steps of data preprocessing?\n",
      "AI Answer: Here are the steps of data preprocessing:\n",
      "\n",
      "1. Data cleaning: This involves removing irrelevant or duplicate columns, cleaning data for any missing values, and correcting data type inconsistencies.\n",
      "\n",
      "2. Data normalization: This involves standardizing the data to ensure that all variables have a similar distribution. This can be achieved by subtracting the mean and scaling the variables to have a zero mean and unit variance.\n",
      "\n",
      "3. Data splitting: Data splitting is used to create training, testing, and validation sets. It helps in selecting the most relevant information for model selection and ensuring that the training data covers most of the features. The split ratio should be calculated based on the purpose of the project, and it should be no less than 70% or more than 30%.\n",
      "\n",
      "4. Feature engineering: This involves transforming raw data into useful features for machine learning algorithms. The feature engineering process can include various techniques such as encoding categorical variables, transforming numeric variables to continuous values, designing new features based on existing ones, etc.\n",
      "\n",
      "5. Data augmentation: This is a technique used to increase the size of the training set without increasing the computational cost. It involves generating fake data that closely resembles real data.\n",
      "\n",
      "6. Preprocessing for machine learning algorithms: Machine learning algorithms, such as logistic regression, neural networks, and decision trees, require preprocessing beforehand. This can include scaling or normalizing data, removing irrelevant features, or adding redundant ones to the feature set.\n",
      "\n",
      "7. Data visualization: Visualization is a crucial step in data analysis. It helps in understanding patterns, trends, and relationships among different variables. The data visualization process involves selecting relevant metrics, plots, graphs, etc., and displaying them in a clear and concise manner for better understanding.\n",
      "Expected: Data preprocessing involves data cleaning, normalization, transformation, feature selection, and splitting.\n",
      "Similarity Score: 0.79\n",
      "\n",
      "Q5: What is clustering?\n",
      "AI Answer: Clustering is a machine learning technique used to group together observations that have similar characteristics, such as demographics or characteristics. Clustering is useful for data analysis and visualization in many applications including market research, customer segmentation, and product recommendation. In general, clustering involves applying statistical algorithms to the dataset to identify groups of similar observations.\n",
      "\n",
      "Cluster assignments can be visualized using different techniques such as heuristic algorithms or clustering trees, which are commonly used in practice. Heuristic algorithms use local search methods to find a near-optimal solution while clustering trees are used for more structured groupings.\n",
      "\n",
      "In the context of real-world applications, clustering is often used in social sciences and psychology to analyze large datasets such as survey data or customer interactions. Clustering can also be useful in industries such as retail or finance to categorize customers into groups based on demographics or purchasing behavior.\n",
      "\n",
      "In summary, clustering is a powerful technique for data analysis that can help identify similar patterns and groupings among data.\n",
      "Expected: Clustering is an unsupervised learning technique that groups similar data points.\n",
      "Similarity Score: 0.75\n",
      "\n",
      "‚úÖ Final Accuracy of AI Tutor: 80.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Test Questions & Expected Answers\n",
    "# ------------------------------\n",
    "qa_pairs = [\n",
    "    (\"What is predictive analysis?\", \"Predictive analysis uses historical data and statistical models to predict future outcomes.\"),\n",
    "    (\"What is regression?\", \"Regression is a supervised learning method used to predict continuous values.\"),\n",
    "    (\"What is classification?\", \"Classification is a supervised learning task that assigns data into predefined labels.\"),\n",
    "    (\"What are the steps of data preprocessing?\", \"Data preprocessing involves data cleaning, normalization, transformation, feature selection, and splitting.\"),\n",
    "    (\"What is clustering?\", \"Clustering is an unsupervised learning technique that groups similar data points.\"),\n",
    "]\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Load Similarity Model\n",
    "# ------------------------------\n",
    "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to compute semantic similarity\n",
    "def get_similarity(ans1, ans2):\n",
    "    emb1 = similarity_model.encode([ans1])\n",
    "    emb2 = similarity_model.encode([ans2])\n",
    "    return cosine_similarity(emb1, emb2)[0][0]\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Accuracy Test\n",
    "# ------------------------------\n",
    "correct = 0\n",
    "print(\"\\nüîç Starting accuracy test...\\n\")\n",
    "\n",
    "for i, (question, expected) in enumerate(qa_pairs, 1):\n",
    "    # Use your existing chunk search and LLM answering functions\n",
    "    top_chunks = find_top_chunks(question, chunks, model, index, top_n=2)\n",
    "    context = \"\\n\".join(top_chunks)\n",
    "    ai_answer = ask_local_llm(context, question)\n",
    "    \n",
    "    # Calculate similarity\n",
    "    sim = get_similarity(ai_answer, expected)\n",
    "    print(f\"Q{i}: {question}\")\n",
    "    print(f\"AI Answer: {ai_answer}\")\n",
    "    print(f\"Expected: {expected}\")\n",
    "    print(f\"Similarity Score: {sim:.2f}\\n\")\n",
    "    \n",
    "    if sim > 0.7:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = (correct / len(qa_pairs)) * 100\n",
    "print(f\"‚úÖ Final Accuracy of AI Tutor: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
